{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee9b6adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import warnings\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from six.moves import urllib\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77016eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://127.0.0.2:5000'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mlflow server --backend-store-uri mlruns/ --default-artifact-root mlruns/ --host 127.0.0.2 --port 5000\n",
    "remote_server_uri = \"http://127.0.0.2:5000\"\n",
    "mlflow.set_tracking_uri(remote_server_uri)\n",
    "mlflow.tracking.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "707ec496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/05/06 12:45:16 INFO mlflow.tracking.fluent: Experiment with name 'Housing_Price_Prediction_Experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlruns/1', experiment_id='1', lifecycle_stage='active', name='Housing_Price_Prediction_Experiment', tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = \"Housing_Price_Prediction_Experiment\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f4b416c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Random Forest Model --\n",
      "\n",
      "  RMSE: 47682.77540712766\n",
      "  MAE: 31769.932299741602\n",
      "  R2: 0.8255489237395524\n",
      "Save to: mlruns/1/077c27f2ed7144118f990217764d4355/artifacts\n",
      "\n",
      "-- Linear Regression Model --\n",
      "\n",
      "  RMSE: 68627.87390018745\n",
      "  MAE: 49438.66860915801\n",
      "  R2: 0.6481553634454353\n",
      "Save to: mlruns/1/7873268912ac4465b761928a29baf0b5/artifacts\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"PARENT_RUN\") as parent_run:\n",
    "    mlflow.log_param(\"parent\", \"yes\")\n",
    "    with mlflow.start_run(run_name=\"MATRIX_EVALUATION\", nested=True) as child_run:\n",
    "        mlflow.log_param(\"child\", \"yes\")\n",
    "\n",
    "        def eval_metrics(actual, pred):\n",
    "            # compute relevant metrics\n",
    "            rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "            mae = mean_absolute_error(actual, pred)\n",
    "            r2 = r2_score(actual, pred)\n",
    "            return rmse, mae, r2\n",
    "\n",
    "    with mlflow.start_run(run_name=\"LOADING_DATA\", nested=True) as child_run:\n",
    "        mlflow.log_param(\"child\", \"yes\")\n",
    "\n",
    "        def load_data():\n",
    "\n",
    "            DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "            HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "            HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "            def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "                if not os.path.isdir(housing_path):\n",
    "                    os.makedirs(housing_path)\n",
    "                tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "                urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "                housing_tgz = tarfile.open(tgz_path)\n",
    "                housing_tgz.extractall(path=housing_path)\n",
    "                housing_tgz.close()\n",
    "\n",
    "            def load_housing_data(housing_path=HOUSING_PATH):\n",
    "                csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "                return pd.read_csv(csv_path)\n",
    "\n",
    "            fetch_housing_data()\n",
    "            housing = load_housing_data()\n",
    "            return housing\n",
    "\n",
    "    with mlflow.start_run(run_name=\"SAMPLING_DATA\", nested=True) as child_run:\n",
    "        mlflow.log_param(\"child\", \"yes\")\n",
    "        # categorizing median income to perform stratified sampling.\n",
    "        housing = load_data()\n",
    "        housing[\"income_cat\"] = pd.cut(\n",
    "            housing[\"median_income\"], bins=[0.0, 1.5, 3.0, 4.5, 6.0, np.inf], labels=[1, 2, 3, 4, 5],\n",
    "        )\n",
    "\n",
    "        # Performing stratified sampling.\n",
    "\n",
    "        split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "        for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "            strat_train_set = housing.loc[train_index]\n",
    "            strat_test_set = housing.loc[test_index]\n",
    "        for set_ in (strat_train_set, strat_test_set):\n",
    "            set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "\n",
    "        housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "        housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "    with mlflow.start_run(run_name=\"CLEANING_DATA\", nested=True) as child_run:\n",
    "        mlflow.log_param(\"child\", \"yes\")\n",
    "\n",
    "        # Data cleaning\n",
    "\n",
    "        imputer = SimpleImputer(strategy=\"median\")\n",
    "        housing_num = housing.drop(\"ocean_proximity\", axis=1)  # Dropped Ocean_Proximity as it is a non-numeric column.\n",
    "        imputer.fit(housing_num)\n",
    "        X = imputer.transform(housing_num)\n",
    "        housing_tr = pd.DataFrame(X, columns=housing_num.columns)\n",
    "        housing_cat = housing[[\"ocean_proximity\"]]\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "        cat_encoder = OneHotEncoder()\n",
    "        housing_cat_1hot = cat_encoder.fit_transform(housing_cat)  # Creating Dummy clomns for non-numeric data\n",
    "\n",
    "    with mlflow.start_run(run_name=\"CUSTOM_TRANSFORMER\", nested=True) as child_run:\n",
    "        mlflow.log_param(\"child\", \"yes\")\n",
    "        from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "        rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "\n",
    "        class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "            def __init__(self, add_bedrooms_per_room=True):  # no *args or **kargs\n",
    "                self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "\n",
    "            def fit(self, X, y=None):\n",
    "                return self  # nothing else to do\n",
    "\n",
    "            def transform(self, X, y=None):\n",
    "                rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "                population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "                if self.add_bedrooms_per_room:\n",
    "                    bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "                    return np.c_[\n",
    "                        X, rooms_per_household, population_per_household, bedrooms_per_room,\n",
    "                    ]\n",
    "                else:\n",
    "                    return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "        attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "        housing_extra_attribs = attr_adder.transform(housing.values)\n",
    "\n",
    "    with mlflow.start_run(run_name=\"PIPELINE\", nested=True) as child_run:\n",
    "        mlflow.log_param(\"child\", \"yes\")\n",
    "\n",
    "        # Transformation Pipelines\n",
    "\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "        num_pipeline = Pipeline(\n",
    "            [\n",
    "                (\"imputer\", SimpleImputer(strategy=\"median\"),),  # Imputing missing values\n",
    "                (\"attribs_adder\", CombinedAttributesAdder(),),  # combining attributes to make them logical\n",
    "                (\"std_scaler\", StandardScaler()),  # Standardising features\n",
    "            ]\n",
    "        )\n",
    "        housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "\n",
    "        # Full pipeline for both categorical and numerical data columns\n",
    "\n",
    "        from sklearn.compose import ColumnTransformer\n",
    "\n",
    "        num_attribs = list(housing_num)\n",
    "        cat_attribs = [\"ocean_proximity\"]\n",
    "        full_pipeline = ColumnTransformer([(\"num\", num_pipeline, num_attribs), (\"cat\", OneHotEncoder(), cat_attribs)])\n",
    "        housing_prepared = full_pipeline.fit_transform(housing)\n",
    "    with mlflow.start_run(run_name=\"TRAINING_MODEL\", nested=True) as child_run:\n",
    "        mlflow.log_param(\"child\", \"yes\")\n",
    "        # train a model with given parameters\n",
    "\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        np.random.seed(40)\n",
    "\n",
    "        # Making a Random Forest Model\n",
    "\n",
    "        with mlflow.start_run(run_name=\"RANDOM_FOREST_MODEL\", nested=True) as child_run:\n",
    "            mlflow.log_param(\"child\", \"yes\")\n",
    "            from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "            forest_reg = RandomForestRegressor()\n",
    "            forest_reg.fit(housing_prepared, housing_labels)\n",
    "            housing_predictions = forest_reg.predict(housing_prepared)\n",
    "\n",
    "            # Performing Grid Search\n",
    "\n",
    "            from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "            param_grid = [\n",
    "                {\"n_estimators\": [3, 10, 30], \"max_features\": [2, 4, 6, 8]},\n",
    "                {\"bootstrap\": [False], \"n_estimators\": [3, 10], \"max_features\": [2, 3, 4]},\n",
    "            ]\n",
    "            forest_reg = RandomForestRegressor()\n",
    "            grid_search = GridSearchCV(\n",
    "                forest_reg, param_grid, cv=5, scoring=\"neg_mean_squared_error\", return_train_score=True,\n",
    "            )\n",
    "            grid_search.fit(housing_prepared, housing_labels)\n",
    "            cvres = grid_search.cv_results_\n",
    "            feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "            feature_importances\n",
    "\n",
    "            extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
    "            cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "            cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "            attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "            sorted(zip(feature_importances, attributes), reverse=True)\n",
    "\n",
    "            final_model = grid_search.best_estimator_\n",
    "            X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "            y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "            X_test_prepared = full_pipeline.transform(X_test)\n",
    "            final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "            # Evaluate Metrics\n",
    "\n",
    "            (rmse, mae, r2) = eval_metrics(y_test, final_predictions)\n",
    "\n",
    "            print(\"\\n-- Random Forest Model --\\n\")\n",
    "            print(\"  RMSE: %s\" % rmse)\n",
    "            print(\"  MAE: %s\" % mae)\n",
    "            print(\"  R2: %s\" % r2)\n",
    "\n",
    "            # metrics, and model to MLflow\n",
    "            mlflow.log_param(\"Model\", \"Random Forest Model\")\n",
    "            mlflow.log_metric(key=\"rmse\", value=rmse)\n",
    "            mlflow.log_metrics({\"mae\": mae, \"r2\": r2})\n",
    "            print(\"Save to: {}\".format(mlflow.get_artifact_uri()))\n",
    "\n",
    "            mlflow.sklearn.log_model(forest_reg, \"model\")\n",
    "\n",
    "        with mlflow.start_run(run_name=\"LINEAR_REGRESSION_MODEL\", nested=True) as child_run:\n",
    "            mlflow.log_param(\"child\", \"yes\")\n",
    "            from sklearn.linear_model import LinearRegression\n",
    "\n",
    "            lin_reg = LinearRegression()\n",
    "            lin_reg.fit(housing_prepared, housing_labels)\n",
    "\n",
    "            housing_predictions = lin_reg.predict(housing_prepared)\n",
    "\n",
    "            # Evaluate Metrics\n",
    "\n",
    "            (rmse, mae, r2) = eval_metrics(housing_labels, housing_predictions)\n",
    "\n",
    "            print(\"\\n-- Linear Regression Model --\\n\")\n",
    "            print(\"  RMSE: %s\" % rmse)\n",
    "            print(\"  MAE: %s\" % mae)\n",
    "            print(\"  R2: %s\" % r2)\n",
    "\n",
    "            # metrics, and model to MLflow\n",
    "            mlflow.log_param(\"Model\", \"Linear Regression Model\")\n",
    "            mlflow.log_metric(key=\"rmse\", value=rmse)\n",
    "            mlflow.log_metrics({\"mae\": mae, \"r2\": r2})\n",
    "            print(\"Save to: {}\".format(mlflow.get_artifact_uri()))\n",
    "            mlflow.sklearn.log_model(lin_reg, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701a28a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
